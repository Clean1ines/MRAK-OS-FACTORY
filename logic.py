from dotenv import load_dotenv
import os
import re
import httpx
from groq import Groq

load_dotenv()


class MrakOrchestrator:
    def __init__(self, api_key=None):
        self.api_key = api_key or os.getenv("GROQ_API_KEY")
        self.gh_token = os.getenv("GH_TOKEN")
        self.client = Groq(
            api_key=self.api_key, http_client=httpx.Client(timeout=120.0)
        )
        self.base_url = "https://api.groq.com/openai/v1"

        # -----------------------------------------------------------------
        # –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∂–∏–º–æ–≤.
        # –ö–∞–∂–¥—ã–π –∫–ª—é—á ‚Äì —É—Å–ª–æ–≤–Ω—ã–π –∫–æ–¥ —Ä–µ–∂–∏–º–∞, –∞ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äì –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        # –æ–∫—Ä—É–∂–µ–Ω–∏—è, —Å–æ–¥–µ—Ä–∂–∞—â–µ–π URL‚Äë—Ñ–∞–π–ª–∞ —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º.
        # –£–¥–∞–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ .env,
        # –∞ —Ç–∞–∫–∂–µ –∑–∞–º–µ–Ω—ë–Ω —É—Å—Ç–∞—Ä–µ–≤—à–∏–π GH_PROMPT_URL –Ω–∞ SYSTEM_PROMPT_URL.
        # -----------------------------------------------------------------
        self.mode_map = {
            # Core / –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            "01_CORE": "SYSTEM_PROMPT_URL",

            # UI/UX
            "02_UI_UX": "GH_URL_UI_UX",

            # Software Engineering
            "03_SOFT_ENG": "GH_URL_SOFT_ENG",

            # Failure detection
            "04_FAILURE": "GH_URL_FAILURE",

            # Translator
            "06_TRANSLATOR": "GH_URL_TRANSLATOR",

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ .env
            "07_INTEGRATION_PLAN": "GH_URL_INTEGRATION_PLAN",
            "08_PROMPT_COUNCIL": "GH_URL_PROMPT_COUNCIL",
            "09_ALGO_COUNCIL": "GH_URL_ALGO_COUNCIL",
            "10_FULL_CODE_GEN": "GH_URL_FULL_CODE_GEN",
            "11_REQ_COUNCIL": "GH_URL_REQ_COUNCIL",
            "12_SELF_ANALYSIS_FACTORY": "GH_URL_SELF_ANALYSIS_FACTORY",
        }

    # -----------------------------------------------------------------
    # –û—Å—Ç–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å –∫–ª–∞—Å—Å–∞ –æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    # -----------------------------------------------------------------
    def get_active_models(self):
        fallback_models = [
            {"id": "openai/gpt-oss-120b"},
            {"id": "llama-3.3-70b-versatile"},
            {"id": "llama-3.1-8b-instant"},
            {"id": "groq/compound"},
            {"id": "qwen/qwen3-32b"},
        ]
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        try:
            with httpx.Client() as client:
                response = client.get(
                    f"{self.base_url}/models", headers=headers, timeout=10.0
                )
                if response.status_code == 200:
                    data = response.json()
                    active = [
                        {"id": m["id"]}
                        for m in data.get("data", [])
                        if "whisper" not in m["id"]
                    ]
                    return active if active else fallback_models
                return fallback_models
        except Exception:
            return fallback_models

    async def get_system_prompt(self, mode: str):
        if mode == "07_BYPASS":
            return "You are a helpful assistant."
        env_var = self.mode_map.get(mode, "SYSTEM_PROMPT_URL")
        url = os.getenv(env_var)
        if not (self.gh_token and url):
            return "System Error: Config Missing."
        headers = {
            "Authorization": f"token {self.gh_token}",
            "Accept": "application/vnd.github.v3.raw",
        }
        async with httpx.AsyncClient() as c:
            try:
                r = await c.get(url, headers=headers, timeout=15)
                if r.status_code == 200:
                    return r.text.strip()
                return f"Error: {r.status_code}"
            except Exception as e:
                return f"Connection Error: {str(e)}"

    def _pii_filter(self, text: str) -> str:
        text = re.sub(r"[\w\.-]+@[\w\.-]+\.\w+", "[EMAIL_REDACTED]", text)
        text = re.sub(r"(gsk_|sk-)[a-zA-Z0-9]{20,}", "[KEY_REDACTED]", text)
        return text

    def stream_analysis(self, user_input: str, system_prompt: str, model_id: str):
        clean_input = self._pii_filter(user_input)
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
            raw_res = self.client.chat.completions.with_raw_response.create(
                model=model_id,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": clean_input},
                ],
                stream=True,
                temperature=0.6,
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ª–∏–º–∏—Ç—ã
            rt = raw_res.headers.get("x-ratelimit-remaining-tokens", "---")
            rr = raw_res.headers.get("x-ratelimit-remaining-requests", "---")
            yield f"__METADATA__{rt}|{rr}__"

            # –°—Ç—Ä–∏–º–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç
            for chunk in raw_res.parse():
                if chunk.choices and chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            err_msg = str(e).lower()
            if "403" in err_msg:
                yield "üî¥ **ACCESS_DENIED**: API –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ."
            elif "429" in err_msg:
                yield "üî¥ **RATE_LIMIT**: –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –ª–∏–º–∏—Ç—ã –∏—Å—á–µ—Ä–ø–∞–Ω—ã."
            else:
                yield f"üî¥ **GROQ_API_ERROR**: {str(e)}"